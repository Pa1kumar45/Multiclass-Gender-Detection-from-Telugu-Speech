{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6737ovZATr5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "from google.colab import drive, files\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "id": "UHzW3MmEAY_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_folder = \"/content/drive/MyDrive/Trans total converted_wav/Trans total converted_wav\"\n",
        "\n",
        "existing_excel = \"/content/drive/MyDrive/PAS_Features(new).xlsx\""
      ],
      "metadata": {
        "id": "z0QOy-7mAY8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pitch(y, sr=16000, fmin=75.0, fmax=400.0):\n",
        "    try:\n",
        "        f0 = librosa.yin(y, fmin=fmin, fmax=fmax, sr=sr, frame_length=2048, hop_length=256)\n",
        "        voiced = f0[~np.isnan(f0)]\n",
        "        return float(np.median(voiced)) if len(voiced) > 0 else 0.0\n",
        "    except:\n",
        "        return 0.0\n"
      ],
      "metadata": {
        "id": "6YW1uegUAY6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mfcc(y, sr=16000, n_mfcc=10, fixed_length=40000):\n",
        "    y = librosa.to_mono(y)\n",
        "    y = y[:fixed_length]\n",
        "    if len(y) < fixed_length:\n",
        "        y = np.pad(y, (0, fixed_length - len(y)), 'constant')\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, hop_length=4000)\n",
        "    mfcc_flat = mfcc.flatten()\n",
        "    desired_len = 110\n",
        "    if len(mfcc_flat) < desired_len:\n",
        "        mfcc_flat = np.pad(mfcc_flat, (0, desired_len - len(mfcc_flat)), 'constant')\n",
        "    else:\n",
        "        mfcc_flat = mfcc_flat[:desired_len]\n",
        "    return mfcc_flat"
      ],
      "metadata": {
        "id": "Fj_ffQIxAY4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_features = []\n",
        "counter = 0\n",
        "\n",
        "for audio_file in os.listdir(trans_folder):\n",
        "    if audio_file.endswith('.wav'):\n",
        "        file_path = os.path.join(trans_folder, audio_file)\n",
        "        try:\n",
        "            y, sr = librosa.load(file_path, sr=16000, mono=True)\n",
        "            pitch = get_pitch(y, sr)\n",
        "            mfcc_features = get_mfcc(y, sr)\n",
        "            trans_features.append([file_path, pitch] + mfcc_features.tolist() + ['trans'])\n",
        "            counter += 1\n",
        "            print(f\"Processed {counter} trans files\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "print(f\"\\n Total trans features extracted: {len(trans_features)}\")"
      ],
      "metadata": {
        "id": "tLJOjEVEAY2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(existing_excel):\n",
        "    existing_df = pd.read_excel(existing_excel)\n",
        "    print(f\"Loaded existing dataset with {len(existing_df)} samples.\")\n",
        "else:\n",
        "    print(\"Existing Excel file not found. Creating new one.\")\n",
        "    columns = ['audio_file', 'pitch'] + [f'mfcc{i}' for i in range(1, 111)] + ['gender']\n",
        "    existing_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "columns = ['audio_file', 'pitch'] + [f'mfcc{i}' for i in range(1, 111)] + ['gender']\n",
        "trans_df = pd.DataFrame(trans_features, columns=columns)\n",
        "\n",
        "combined_df = pd.concat([existing_df, trans_df], ignore_index=True)\n",
        "print(f\"\\n Final dataset size: {len(combined_df)} samples\")"
      ],
      "metadata": {
        "id": "Syd7JbLSAY0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/extracted_features_withtrans(new).xlsx'\n",
        "combined_df.to_excel(save_path, index=False)\n",
        "print(f\"\\n Saved combined features to Drive at: {save_path}\")\n"
      ],
      "metadata": {
        "id": "tGc0FbxxAYyL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}